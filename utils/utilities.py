import numpy as np
import numba
from numba import njit, prange

@numba.njit(cache=True, parallel=True)
def gauss_pdf_numba(points, mean, cov_inv, cov_det):
    """
    JIT-compiled multivariate Gaussian PDF computation.
    
    Args:
        points: (N, 2) array of points
        mean: (2,) mean vector
        cov_inv: (2, 2) pre-computed inverse covariance
        cov_det: float, pre-computed covariance determinant
    
    Returns:
        prob: (N,) probability values
    """
    n_points = points.shape[0]
    prob = np.empty(n_points)
    coefficient = 1.0 / np.sqrt((2.0 * np.pi) ** 2 * cov_det)
    
    for i in numba.prange(n_points):
        diff_x = points[i, 0] - mean[0]
        diff_y = points[i, 1] - mean[1]
        
        # Compute (diff @ cov_inv) @ diff.T efficiently
        temp_x = diff_x * cov_inv[0, 0] + diff_y * cov_inv[1, 0]
        temp_y = diff_x * cov_inv[0, 1] + diff_y * cov_inv[1, 1]
        exponent = -0.5 * (temp_x * diff_x + temp_y * diff_y)
        
        prob[i] = coefficient * np.exp(exponent)
    
    return prob


def gauss_pdf(x, y, mean, covariance):
    """
    Wrapper for Gaussian PDF that pre-computes matrix operations.
    """
    points = np.column_stack([x.flatten(), y.flatten()])
    cov_inv = np.linalg.inv(covariance)
    cov_det = np.linalg.det(covariance)
    return gauss_pdf_numba(points, mean, cov_inv, cov_det)


def gmm_pdf(x, y, means, covariances, weights):
    """
    Evaluate a Gaussian Mixture Model (GMM) PDF at given points.
    
    Args:
        x: x-coordinates (can be scalar, 1D array, or 2D meshgrid)
        y: y-coordinates (can be scalar, 1D array, or 2D meshgrid)
        weights: array of mixture weights (should sum to 1)
        means: array of shape (n_components, 2) - mean vectors
        covariances: array of shape (n_components, 2, 2) - covariance matrices
    
    Returns:
        prob: probability values evaluated at (x, y)
    """
    prob = 0.0
    for i in range(len(weights)):
        prob += weights[i] * gauss_pdf(x, y, means[i], covariances[i])
    return prob

def compute_voronoi_region(xy_grid, robot_positions, robot_idx, robot_range, grid_spacing):
  """
  Compute which grid points belong to robot i's Voronoi region.
  
  Args:
      robot_positions: array of shape (n_robots, 2)
      robot_idx: index of the robot
  
  Returns:
      Boolean mask indicating points in Voronoi region
  """
  # Compute distances from all grid points to all robots
  dists = np.linalg.norm(
      xy_grid[:, np.newaxis, :] - robot_positions[np.newaxis, :, :],
      axis=2
  )
  
  # Points belong to robot i if it's the closest
  closest_robot = np.argmin(dists, axis=1)
  voronoi_mask = (closest_robot == robot_idx)

  # limit to range
  robot = robot_positions[robot_idx]
  dists_to_robot = np.linalg.norm(xy_grid - robot, axis=1)
  voronoi_mask = np.logical_and(voronoi_mask, dists_to_robot <= robot_range * grid_spacing)
  
  return voronoi_mask

@numba.njit(parallel=True, cache=True)
def compute_voronoi_partitioning(xy_grid, robot_positions, robot_range):
    n_points = xy_grid.shape[0]
    n_robots = robot_positions.shape[0]
    
    # Compute squared distances manually (faster, Numba-compatible)
    dists_sq = np.empty((n_points, n_robots))
    for i in numba.prange(n_points):
        for j in range(n_robots):
            dx = xy_grid[i, 0] - robot_positions[j, 0]
            dy = xy_grid[i, 1] - robot_positions[j, 1]
            dists_sq[i, j] = dx * dx + dy * dy
    
    closest = np.argmin(dists_sq, axis=1)
    
    masks = []
    range_sq = robot_range * robot_range
    for i in range(n_robots):
        mask = (closest == i)
        mask &= (dists_sq[:, i] <= range_sq)
        masks.append(mask)
    
    return masks